{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a329f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed for reproducibility\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a790a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo Data Setup\n",
    "# -------------------------------\n",
    "# 0. CONFIGURATION\n",
    "# -------------------------------\n",
    "num_gt        = 1000               # Number of ground‑truth parameter draws\n",
    "num_samples   = 100               # Posterior samples per GT\n",
    "n             = 100               # Observations per GT\n",
    "true_sigma    = 1.0               # Observation noise σ\n",
    "prior_mu      = np.zeros(2)       # Prior mean vector [m0, b0]\n",
    "prior_Sigma   = np.eye(2) * 1.0   # Prior covariance (τ² I)\n",
    "noise_levels  = [0.001, 0.01, 0.1, 0.15, 0.2, 0.25]\n",
    "num_noise     = len(noise_levels)\n",
    "curr_num_runs = 100\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Storage\n",
    "# -------------------------------\n",
    "# ground_truths: shape (num_gt, 2) for [m*, b*]\n",
    "# ground_truths = np.random.uniform(-5, 5, size=(num_gt, 2))\n",
    "# m_stars       = np.random.uniform(-1,  1, size=num_gt)\n",
    "# b_stars       = np.random.uniform(-5,  5, size=num_gt)\n",
    "m_stars       = np.random.normal(loc=0.0, scale=0.5, size=num_gt)  # e.g., mean=0, std=0.5\n",
    "b_stars       = np.random.normal(loc=0.0, scale=2.0, size=num_gt)  # e.g., mean=0, std=2.0\n",
    "ground_truths = np.stack([m_stars, b_stars], axis=1)  # shape (num_gt, 2)\n",
    "\n",
    "# posteriors: shape (num_noise, num_gt, num_samples, 2)\n",
    "posteriors = np.zeros((num_noise, num_gt, num_samples, 2))\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Posterior Sampling Loop\n",
    "# -------------------------------\n",
    "# Initialize empty list to hold TARP-compatible posteriors\n",
    "tarp_posteriors = [np.zeros((num_samples, num_gt, 2)) for _ in range(num_noise)]\n",
    "\n",
    "for gt_idx in tqdm(range(num_gt), desc=\"Sampling Linear-Regression Posteriors\"):\n",
    "    m_star, b_star = ground_truths[gt_idx]\n",
    "    \n",
    "    # Generate data\n",
    "    x = np.random.uniform(-1, 1, size=n)\n",
    "    y = m_star * x + b_star + np.random.normal(0, true_sigma, size=n)\n",
    "    \n",
    "    # Build design matrix\n",
    "    A = np.stack([x, np.ones(n)], axis=1)  # shape (n, 2)\n",
    "    \n",
    "    # Compute posterior\n",
    "    Sigma_n_inv = np.eye(n) / (true_sigma**2)\n",
    "    Precision_post = np.linalg.inv(prior_Sigma) + A.T @ Sigma_n_inv @ A\n",
    "    Sigma_post     = np.linalg.inv(Precision_post)\n",
    "    mu_post        = Sigma_post @ (A.T @ Sigma_n_inv @ y + np.linalg.inv(prior_Sigma) @ prior_mu)\n",
    "    \n",
    "    # Draw biased samples for each noise level (i.e., model)\n",
    "    for nl_idx, scale in enumerate(noise_levels):\n",
    "        delta = np.sqrt(scale) * np.array([1.0, 1.0])  # Bias for m, b\n",
    "        # biased_mean = mu_post + delta\n",
    "        # samples = np.random.multivariate_normal(biased_mean, Sigma_post, size=num_samples)\n",
    "\n",
    "        # Example miscalibration\n",
    "        delta = np.sqrt(scale) * np.array([1.0, 1.0])\n",
    "        biased_mean = mu_post + delta\n",
    "        variance_scale = 1.0 + scale  # inflate covariance for miscalibration\n",
    "        biased_cov = Sigma_post * variance_scale\n",
    "        samples = np.random.multivariate_normal(biased_mean, biased_cov, size=num_samples)\n",
    "        \n",
    "        # Store in the correct slot: (samples, ground_truth_idx, dim)\n",
    "        tarp_posteriors[nl_idx][:, gt_idx, :] = samples\n",
    "\n",
    "# Normalize for each ground-truth index independently\n",
    "gt_norm = np.zeros_like(ground_truths)\n",
    "tarp_posteriors_norm = []\n",
    "\n",
    "for model in tarp_posteriors:\n",
    "    model_norm = np.zeros_like(model)\n",
    "    for t in range(num_gt):\n",
    "        post_t = model[:, t, :]\n",
    "        gt_t = ground_truths[t]\n",
    "\n",
    "        combined = np.vstack([post_t, gt_t[None, :]])\n",
    "        min_vals = combined.min(axis=0)\n",
    "        max_vals = combined.max(axis=0)\n",
    "        ranges = np.maximum(max_vals - min_vals, 1e-8)\n",
    "\n",
    "        model_norm[:, t, :] = post_t  # Keep original scale\n",
    "        gt_norm[t, :] = gt_t\n",
    "\n",
    "    tarp_posteriors_norm.append(model_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e473413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Tarp on LR\n",
    "# Store TARP-compatible posteriors in a list or dict\n",
    "from tarp import get_tarp_coverage\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Ideal')\n",
    "k_sigma = [1]\n",
    "all_ecp_means = []\n",
    "all_ecp_stds = []\n",
    "for i in range(0, len(tarp_posteriors)):\n",
    "    print(f'Noise Model: {noise_levels[i]}')\n",
    "\n",
    "    # TARP with bootstrapping\n",
    "    ecp_boot, alpha = get_tarp_coverage(tarp_posteriors[i].copy(), gt_norm.copy(), bootstrap=True, num_bootstrap=100, norm=True)\n",
    "    ecp_mean = ecp_boot.mean(axis=0)\n",
    "    ecp_std = ecp_boot.std(axis=0)\n",
    "    all_ecp_means.append(ecp_mean)\n",
    "    all_ecp_stds.append(ecp_std)\n",
    "    plt.plot(alpha, ecp_mean, label=f'Noise Level: {noise_levels[i]}', alpha=0.8)\n",
    "    for k in k_sigma:\n",
    "        plt.fill_between(alpha, ecp_mean - k * ecp_std, ecp_mean + k * ecp_std, alpha=0.3)\n",
    "\n",
    "all_ecp_means = np.array(all_ecp_means)  # shape (n_noise_levels, n_alpha)\n",
    "all_ecp_stds = np.array(all_ecp_stds)\n",
    "np.savez(\n",
    "    './LR_TARP_Bootstrap_Data/LR_TARP_Bootstrap_Data.npz',\n",
    "    alpha=alpha,\n",
    "    noise_levels=noise_levels,\n",
    "    ecp_means=all_ecp_means,\n",
    "    ecp_stds=all_ecp_stds\n",
    ")\n",
    "\n",
    "# Finalize plot\n",
    "plt.xlabel(\"Credibility Level\", fontsize=28)\n",
    "plt.ylabel(\"Expected Coverage\", fontsize=28)\n",
    "plt.xticks(fontsize=21)\n",
    "plt.yticks(fontsize=21)\n",
    "plt.legend(fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./PNG_Plots/LR_TARP_Bootstrap_Plot.png\", dpi=300)\n",
    "plt.savefig(\"./PDF_Plots/LR_TARP_Bootstrap_Plot.pdf\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480f879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10441e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tarp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
