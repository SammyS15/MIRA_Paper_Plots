{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Notebook\n",
    "\n",
    "This notebook generates all figures for the ICML 2026 paper. It contains plotting functions and visualizations for TARP experiments, GMM model shift analysis, InverseBench experiments, and more.\n",
    "\n",
    "**Author:** Justine\n",
    "\n",
    "**Data Directory:** `../data/`\n",
    "**Output Directories:** `../plots/pdf/` and `../plots/png/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Consolidated imports, style configuration, and plotting utilities.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "\n",
    "CONFERENCE_NAME = \"ICML 2026\"  # Change as needed\n",
    "\n",
    "# Set style and fonts\n",
    "sns.set_theme(style=\"whitegrid\", palette=None)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "\n",
    "if CONFERENCE_NAME == 'ICLR 2026' or CONFERENCE_NAME == 'ICML 2026':\n",
    "    plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "elif CONFERENCE_NAME == 'NeurIPS 2026':\n",
    "    print(f'Please check and come back to update the script for {CONFERENCE_NAME}.')\n",
    "    # Throw an Error to remind user to update font settings\n",
    "    raise ValueError(f\"Font settings not configured for {CONFERENCE_NAME}\")\n",
    "elif CONFERENCE_NAME == 'AISTATS 2026':\n",
    "    print(f'Please check and come back to update the script for {CONFERENCE_NAME}.')\n",
    "    raise ValueError(f\"Font settings not configured for {CONFERENCE_NAME}\")\n",
    "else:\n",
    "    print(f'Please look up the conference font and update this script for {CONFERENCE_NAME}.')\n",
    "    raise ValueError(f\"Font settings not configured for {CONFERENCE_NAME}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Style Configuration\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class PlotStyle:\n",
    "    \"\"\"Centralized style configuration for all plots.\"\"\"\n",
    "    fontsize: int = 20\n",
    "    decrease_size: int = 2\n",
    "    lw: float = 2.0\n",
    "    alpha: float = 0.8\n",
    "    fill_alpha: float = 0.2\n",
    "    markersize: float = 18\n",
    "    markeredgewidth: float = 5\n",
    "    elinewidth: float = 3\n",
    "    capsize: float = 15\n",
    "    tick_color: str = 'black'\n",
    "    \n",
    "    @property\n",
    "    def x_label_fontsize(self) -> int:\n",
    "        return self.fontsize\n",
    "    \n",
    "    @property\n",
    "    def y_label_fontsize(self) -> int:\n",
    "        return self.fontsize\n",
    "    \n",
    "    @property\n",
    "    def tick_fontsize(self) -> int:\n",
    "        return self.fontsize - self.decrease_size\n",
    "    \n",
    "    @property\n",
    "    def legend_fontsize(self) -> int:\n",
    "        return self.fontsize - self.decrease_size - 3\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Color Utilities\n",
    "# =============================================================================\n",
    "\n",
    "def get_diverse_icefire_colors(n: int = 10) -> Tuple[List, List[str]]:\n",
    "    \"\"\"Generate n diverse colors from the icefire colormap.\"\"\"\n",
    "    cmap = sns.color_palette(\"icefire\", as_cmap=True)\n",
    "    positions = np.linspace(0, 1, n)\n",
    "    colors = [cmap(pos) for pos in positions]\n",
    "    return colors, [mcolors.to_hex(c) for c in colors]\n",
    "\n",
    "\n",
    "def visualize_color_palette(colors_hex: List[str], title: str = \"Selected Colors\"):\n",
    "    \"\"\"Display a color palette for reference.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, len(colors_hex) * 0.5))\n",
    "    for i, hex_color in enumerate(colors_hex):\n",
    "        ax.barh(i, 1, color=hex_color)\n",
    "        ax.text(1.05, i, f'{i}: {hex_color}', va='center', fontsize=12)\n",
    "    ax.set_xlim(0, 2)\n",
    "    ax.set_ylim(-0.5, len(colors_hex) - 0.5)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Initialize colors\n",
    "colors, colors_hex = get_diverse_icefire_colors(n=10)\n",
    "\n",
    "# Reference colors for horizontal lines\n",
    "POORLY_CALIBRATED_COLOR = colors_hex[0]\n",
    "WELL_CALIBRATED_COLOR = colors_hex[9]\n",
    "\n",
    "# Data colors (excluding light ends and dark bands)\n",
    "data_colors_hex = [color for i, color in enumerate(colors_hex) if i not in [0, 3, 4, 5]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a9c19",
   "metadata": {},
   "source": [
    "## Color Definitions\n",
    "\n",
    "Hex color palette definitions for consistent plot styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the color palette\n",
    "visualize_color_palette(colors_hex, title='Diversified Icefire Colors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78851a",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Path configuration and data loading verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ItVMcDZ8C1oM",
   "metadata": {
    "id": "ItVMcDZ8C1oM"
   },
   "outputs": [],
   "source": [
    "PATH = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SMsG0qkyC3x9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMsG0qkyC3x9",
    "outputId": "32018878-8c1d-4454-eff9-eb256fda8021"
   },
   "outputs": [],
   "source": [
    "np.load(f'{PATH}/GMM_PQMass/shift_neg_6.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa622c",
   "metadata": {},
   "source": [
    "## Plotting Functions\n",
    "\n",
    "Core plotting functions used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Data Loading Utilities\n",
    "# =============================================================================\n",
    "\n",
    "def load_tarp_results(filepath: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load TARP results from npz file.\n",
    "    Returns dict with 'alpha', 'mean', 'std' keys.\n",
    "    Handles different key naming conventions in the data files.\n",
    "    \"\"\"\n",
    "    data = np.load(filepath)\n",
    "    \n",
    "    # Handle different alpha key names\n",
    "    if 'alpha' in data.files:\n",
    "        alpha = data['alpha']\n",
    "    elif 'alpha_bootstrap' in data.files:\n",
    "        alpha = data['alpha_bootstrap']\n",
    "    else:\n",
    "        raise KeyError(f\"No alpha key found in {filepath}\")\n",
    "    \n",
    "    # Handle different ECP key names\n",
    "    if 'ecp_mean' in data.files:\n",
    "        mean = data['ecp_mean']\n",
    "        std = data['ecp_std']\n",
    "    elif 'ecp_bootstrap' in data.files:\n",
    "        ecp = data['ecp_bootstrap']\n",
    "        mean = ecp.mean(axis=0)\n",
    "        std = ecp.std(axis=0)\n",
    "    elif 'ecp_means' in data.files:\n",
    "        mean = data['ecp_means']\n",
    "        std = data['ecp_stds']\n",
    "    else:\n",
    "        raise KeyError(f\"No ecp key found in {filepath}\")\n",
    "    \n",
    "    return {'alpha': alpha, 'mean': mean, 'std': std}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Core Plotting Functions\n",
    "# =============================================================================\n",
    "\n",
    "def plot_coverage_curve(\n",
    "    ax,\n",
    "    alpha: np.ndarray,\n",
    "    mean: np.ndarray,\n",
    "    std: np.ndarray,\n",
    "    label: str,\n",
    "    color: str,\n",
    "    lw: float = 2.0,\n",
    "    fill_alpha: float = 0.2,\n",
    "    linestyle: str = '-',\n",
    "    std_multiplier: float = 1.0,\n",
    "    line_alpha: float = 1.0,\n",
    "):\n",
    "    \"\"\"Plot a single coverage curve with uncertainty band.\"\"\"\n",
    "    ax.fill_between(\n",
    "        alpha, \n",
    "        mean - std_multiplier * std, \n",
    "        mean + std_multiplier * std, \n",
    "        alpha=fill_alpha, \n",
    "        color=color\n",
    "    )\n",
    "    ax.plot(alpha, mean, linestyle, lw=lw, label=label, color=color, alpha=line_alpha)\n",
    "\n",
    "\n",
    "def plot_coverage_curves(\n",
    "    ax,\n",
    "    curves: List[Dict[str, Any]],\n",
    "    fontsize: int = 40,\n",
    "    decrease_size: int = 2,\n",
    "    lw: float = 2.0,\n",
    "    xlabel: str = \"Credibility Level\",\n",
    "    ylabel: str = \"Expected Coverage\",\n",
    "    show_ideal: bool = True,\n",
    "    xlim: Tuple[float, float] = (0, 1),\n",
    "    ylim: Tuple[float, float] = (0, 1),\n",
    "    show_legend: bool = False,\n",
    "    legend_kwargs: dict = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot multiple coverage curves on a single axis.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "    curves : list of dicts\n",
    "        Each dict should have keys: 'alpha', 'mean', 'std', 'label', 'color'\n",
    "        Optional keys: 'linestyle', 'std_multiplier', 'line_alpha'\n",
    "    \"\"\"\n",
    "    tick_fontsize = fontsize - decrease_size\n",
    "    tick_color = 'black'\n",
    "    \n",
    "    ax.grid(False)\n",
    "    \n",
    "    if show_ideal:\n",
    "        ax.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    \n",
    "    for curve in curves:\n",
    "        plot_coverage_curve(\n",
    "            ax,\n",
    "            curve['alpha'],\n",
    "            curve['mean'],\n",
    "            curve['std'],\n",
    "            curve['label'],\n",
    "            curve['color'],\n",
    "            lw=lw,\n",
    "            linestyle=curve.get('linestyle', '-'),\n",
    "            std_multiplier=curve.get('std_multiplier', 1.0),\n",
    "            line_alpha=curve.get('line_alpha', 1.0),\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "    ax.tick_params(axis='both', labelsize=tick_fontsize, colors=tick_color)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    \n",
    "    if show_legend:\n",
    "        kwargs = {'fontsize': fontsize - decrease_size - 3}\n",
    "        if legend_kwargs:\n",
    "            kwargs.update(legend_kwargs)\n",
    "        ax.legend(**kwargs)\n",
    "\n",
    "\n",
    "def plot_mira_scores(\n",
    "    ax,\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    yerr: np.ndarray,\n",
    "    colors_hex: List[str] = None,\n",
    "    fontsize: int = 20,\n",
    "    decrease_size: int = 2,\n",
    "    xlabel: str = None,\n",
    "    ylabel: str = 'Mira Score',\n",
    "    title: str = None,\n",
    "    show_reference_line: bool = True,\n",
    "    reference_value: float = 0.5,\n",
    "    xtick_labels: List[str] = None,\n",
    "    xtick_rotation: float = 0,\n",
    "    labels: List[str] = None,\n",
    "    lw: float = 5,\n",
    "    markersize: float = 2,\n",
    "    markeredgewidth: float = 2,\n",
    "    elinewidth: float = 2,\n",
    "    alpha: float = 0.5,\n",
    "    capsize: float = 10,\n",
    "    draw_fill: bool = False,\n",
    "    L: int = None,\n",
    "    model_name: str = None,\n",
    "    add_legend: bool = None,\n",
    "    **kwargs,  # Accept additional kwargs for backward compatibility\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot Mira scores with error bars.\n",
    "    Unified function replacing plot_scores_with_error_bars and plot_mira_alone.\n",
    "    \"\"\"\n",
    "    tick_fontsize = fontsize - decrease_size\n",
    "    tick_color = 'black'\n",
    "    \n",
    "    if colors_hex is None:\n",
    "        colors_hex = get_diverse_icefire_colors(10)[1]\n",
    "    \n",
    "    ax.grid(False)\n",
    "    \n",
    "    # Plot error bars\n",
    "    for i in range(len(x)):\n",
    "        label = labels[i] if labels and i < len(labels) else (model_name if model_name else None)\n",
    "        ax.errorbar(\n",
    "            x[i], y[i], yerr=yerr[i], fmt='o',\n",
    "            capsize=capsize,\n",
    "            color=colors_hex[i % len(colors_hex)],\n",
    "            markersize=markersize,\n",
    "            alpha=alpha if not draw_fill else 1.0,\n",
    "            markeredgewidth=markeredgewidth,\n",
    "            elinewidth=elinewidth,\n",
    "            label=label if i == 0 or not model_name else None,\n",
    "        )\n",
    "        print(f'Index {i} | Mira: {y[i]} pm {yerr[i]}')\n",
    "    \n",
    "    # Optional fill between reference lines\n",
    "    if draw_fill and L is not None:\n",
    "        variance = (1/18) / L\n",
    "        std_val = np.sqrt(variance)\n",
    "        x_range = np.linspace(min(x) - 0.5, max(x) + 0.5, 100)\n",
    "        ax.fill_between(x_range, 2/3 - std_val, 2/3 + std_val, alpha=0.2, color='black')\n",
    "        ax.axhline(2/3, color='black', linestyle='--', alpha=1.0, lw=1.5)\n",
    "    \n",
    "    # Reference line for poorly calibrated\n",
    "    if show_reference_line:\n",
    "        ax.axhline(reference_value, color='gray', linestyle='--', alpha=1.0, lw=1.5)\n",
    "    \n",
    "    # Formatting\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=fontsize, fontweight='bold')\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "    ax.tick_params(axis='x', labelsize=tick_fontsize, colors=tick_color)\n",
    "    ax.tick_params(axis='y', labelsize=tick_fontsize, colors=tick_color)\n",
    "    \n",
    "    if xtick_labels is not None:\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(xtick_labels, rotation=xtick_rotation)\n",
    "    \n",
    "    # Show legend if labels were provided\n",
    "    if labels or model_name:\n",
    "        ax.legend(fontsize=fontsize - decrease_size, loc='upper right')\n",
    "\n",
    "\n",
    "def plot_histogram_comparison(\n",
    "    ax,\n",
    "    data_list: List[Tuple[np.ndarray, str, str]],\n",
    "    fontsize: int = 40,\n",
    "    decrease_size: int = 2,\n",
    "    lw: float = 2.0,\n",
    "    xlabel: str = None,\n",
    "    ylabel: str = 'Frequency',\n",
    "    bins: int = 20,\n",
    "    show_chi2: bool = False,\n",
    "    chi2_df: int = 99,\n",
    "    chi2_range: Tuple[float, float] = (60, 160),\n",
    "    legend_kwargs: dict = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot multiple histograms for comparison (e.g., PQMass results).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_list : list of tuples\n",
    "        Each tuple is (data_array, label, color)\n",
    "    \"\"\"\n",
    "    tick_fontsize = fontsize - decrease_size\n",
    "    tick_color = 'black'\n",
    "    \n",
    "    ax.grid(False)\n",
    "    \n",
    "    if show_chi2:\n",
    "        x_chi2 = np.linspace(*chi2_range, 100)\n",
    "        ax.plot(x_chi2, chi2.pdf(x_chi2, df=chi2_df), \n",
    "                lw=lw, label=r'$\\chi^2_{\\mathrm{ideal}}$', color='red')\n",
    "    \n",
    "    for data, label, color in data_list:\n",
    "        ax.hist(data, bins=bins, density=True, label=label, \n",
    "                alpha=0.6, color=color, histtype='stepfilled', linewidth=lw)\n",
    "    \n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "    ax.tick_params(axis='both', labelsize=tick_fontsize, colors=tick_color)\n",
    "    \n",
    "    if legend_kwargs:\n",
    "        ax.legend(**legend_kwargs)\n",
    "\n",
    "\n",
    "def plot_mira_training_curves(\n",
    "    ax,\n",
    "    cache,\n",
    "    models: List[str],\n",
    "    colors_hex: List[str],\n",
    "    L: int = 100,\n",
    "    ylabel: str = 'MIRA Score',\n",
    "    xlabel: str = 'Epoch',\n",
    "    title: str = None,\n",
    "    lw: float = 1.5,\n",
    "    fontsize: int = 20,\n",
    "    markersize_trail: float = 3,\n",
    "    markersize_final: float = 10,\n",
    "    markeredgewidth: float = 1.5,\n",
    "    alpha_trail: float = 0.3,\n",
    "    alpha_final: float = 1.0,\n",
    "    decrease_size: int = 2,\n",
    "    well_calibrated_line: bool = True,\n",
    "    poorly_calibrated_line: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot MIRA score training curves with faded history and bold final points.\n",
    "    \"\"\"\n",
    "    tick_fontsize = fontsize - decrease_size\n",
    "    legend_fontsize = fontsize - decrease_size\n",
    "    \n",
    "    ax.grid(False)\n",
    "    \n",
    "    all_epochs = []\n",
    "    variance = (1/18) / L\n",
    "    std_val = np.sqrt(variance)\n",
    "\n",
    "    # Reference lines\n",
    "    if all_epochs:\n",
    "        x_range = np.linspace(min(all_epochs) - 0.5, max(all_epochs) + 0.5, 100)\n",
    "        if well_calibrated_line:\n",
    "            ax.fill_between(x_range, 2/3 - std_val, 2/3 + std_val, alpha=0.2, color='black')\n",
    "            ax.axhline(2/3, color='black', linestyle='--', lw=lw, alpha=1.0)\n",
    "        if poorly_calibrated_line:\n",
    "            ax.axhline(0.5, color='gray', linestyle='--', lw=lw, alpha=1.0)\n",
    "    \n",
    "    for model, color in zip(models, colors_hex):\n",
    "        # Get model data from cache (handle different key formats)\n",
    "        key_base = model.replace(' ', '_').replace('\\n', '')\n",
    "        epochs_key = f'{key_base}_epochs'\n",
    "        scores_key = f'{key_base}_scores'\n",
    "        \n",
    "        # Try different key patterns\n",
    "        if epochs_key not in cache.files:\n",
    "            epochs_key = f'{model}_epochs'\n",
    "            scores_key = f'{model}_scores'\n",
    "        \n",
    "        if epochs_key not in cache.files:\n",
    "            print(f\"Warning: Could not find data for {model}\")\n",
    "            continue\n",
    "            \n",
    "        epochs = cache[epochs_key]\n",
    "        scores = cache[scores_key]\n",
    "        all_epochs.extend(epochs)\n",
    "        \n",
    "        # Faded training history\n",
    "        ax.plot(epochs, scores, marker='o', lw=lw, color=color,\n",
    "                alpha=alpha_trail, markersize=markersize_trail, label=model)\n",
    "        \n",
    "        # Error band\n",
    "        ax.fill_between(epochs, scores - std_val, scores + std_val,\n",
    "                        color=color, alpha=0.15, linewidth=0)\n",
    "        \n",
    "        # Bold final point\n",
    "        if len(epochs) > 0:\n",
    "            ax.scatter(epochs[-1], scores[-1], s=markersize_final**2, color=color,\n",
    "                       alpha=alpha_final, edgecolors='black',\n",
    "                       linewidth=markeredgewidth/2, zorder=5)\n",
    "\n",
    "    \n",
    "    # Formatting\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=fontsize, fontweight='bold')\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "    ax.tick_params(axis='both', labelsize=tick_fontsize)\n",
    "    ax.legend(fontsize=legend_fontsize, loc='lower right')\n",
    "\n",
    "\n",
    "# Backward compatibility aliases\n",
    "plot_mira_alone = plot_mira_scores\n",
    "plot_scores_with_error_bars = plot_mira_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59280479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Experiment-Specific Plot Functions  \n",
    "# =============================================================================\n",
    "\n",
    "def plot_validation_result(\n",
    "    ax,\n",
    "    experiment_type: str,\n",
    "    data_colors_hex: List[str],\n",
    "    fontsize: int = 40,\n",
    "    decrease_size: int = 2,\n",
    "    lw: float = 2.0,\n",
    "    alpha: float = 0.8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified function to plot validation results for different experiments.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_type : str\n",
    "        One of: 'pqmass', 'linear_regression', 'tarp_figure_2', \n",
    "        'model_misspecification', 'prior_noise_misspecification',\n",
    "        'conditional_distribution', 'inversebench_black_hole',\n",
    "        'inversebench_mri', 'inversebench_scattering'\n",
    "    \"\"\"\n",
    "    \n",
    "    if experiment_type == 'pqmass':\n",
    "        _plot_pqmass(ax, data_colors_hex, fontsize, decrease_size, lw)\n",
    "    elif experiment_type == 'linear_regression':\n",
    "        _plot_linear_regression(ax, data_colors_hex, fontsize, decrease_size, lw)\n",
    "    elif experiment_type == 'tarp_figure_2':\n",
    "        _plot_tarp_figure_2(ax, data_colors_hex, fontsize, decrease_size, lw)\n",
    "    elif experiment_type == 'model_misspecification':\n",
    "        _plot_model_misspecification(ax, data_colors_hex, fontsize, decrease_size, lw)\n",
    "    elif experiment_type == 'prior_noise_misspecification':\n",
    "        _plot_prior_noise_misspecification(ax, data_colors_hex, fontsize, decrease_size, lw, alpha)\n",
    "    elif experiment_type == 'conditional_distribution':\n",
    "        _plot_conditional_distribution(ax, data_colors_hex, fontsize, decrease_size, lw)\n",
    "    elif experiment_type == 'inversebench_black_hole':\n",
    "        _plot_inversebench(ax, 'black_hole_imaging', ['DAPS', 'DiffPIR', 'DPS', 'PnPDM', 'REDDiff'],\n",
    "                          data_colors_hex, fontsize, decrease_size, lw)\n",
    "    elif experiment_type == 'inversebench_mri':\n",
    "        _plot_inversebench(ax, 'compressed_sensing_mri', ['DAPS', 'DiffPIR', 'DPS', 'PnPDM', 'REDDiff'],\n",
    "                          data_colors_hex, fontsize, decrease_size, lw)\n",
    "    elif experiment_type == 'inversebench_scattering':\n",
    "        _plot_inversebench(ax, 'linear_inverse_scattering', \n",
    "                          ['DAPS', 'DDRM', 'DDNM', 'PiGDM', 'DiffPIR', 'DPS', 'PnPDM', 'REDDiff'],\n",
    "                          data_colors_hex, fontsize, decrease_size, lw)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown experiment type: {experiment_type}\")\n",
    "\n",
    "\n",
    "def _plot_pqmass(ax, colors, fontsize, decrease_size, lw):\n",
    "    \"\"\"Plot PQMass chi-squared distribution comparison.\"\"\"\n",
    "    shifts = [('neg_6', -6), ('neg_3', -3), ('zero', 0), ('pos_3', 3), ('pos_6', 6)]\n",
    "    \n",
    "    data_list = []\n",
    "    for i, (name, shift) in enumerate(shifts):\n",
    "        pqmass = np.load(f'{PATH}/GMM_PQMass/shift_{name}.npz')\n",
    "        zs_combined = np.concatenate(pqmass['zs'])\n",
    "        data_list.append((zs_combined, f'Shift: {shift}', colors[i]))\n",
    "    \n",
    "    plot_histogram_comparison(\n",
    "        ax, data_list, fontsize=fontsize, decrease_size=decrease_size, lw=lw,\n",
    "        xlabel=r'$\\chi^2_{{\\rm PQM}}$', show_chi2=True, chi2_df=99,\n",
    "        legend_kwargs={'loc': 'upper right', 'ncol': 3, 'fontsize': fontsize - decrease_size - 3}\n",
    "    )\n",
    "\n",
    "\n",
    "def _plot_linear_regression(ax, colors, fontsize, decrease_size, lw):\n",
    "    \"\"\"Plot linear regression TARP bootstrap results.\"\"\"\n",
    "    lr_data = np.load(f'{PATH}/LR_TARP_Bootstrap_Data/LR_TARP_Bootstrap_Data.npz')\n",
    "    alpha = lr_data['alpha']\n",
    "    noise_levels = lr_data['noise_levels']\n",
    "    ecp_means = lr_data['ecp_means']\n",
    "    ecp_stds = lr_data['ecp_stds']\n",
    "    \n",
    "    curves = []\n",
    "    for i in range(len(noise_levels)):\n",
    "        curves.append({\n",
    "            'alpha': alpha,\n",
    "            'mean': ecp_means[i],\n",
    "            'std': ecp_stds[i],\n",
    "            'label': f\"Noise: {noise_levels[i]:.3f}\",\n",
    "            'color': colors[i % len(colors)],\n",
    "        })\n",
    "    \n",
    "    plot_coverage_curves(ax, curves, fontsize=fontsize, decrease_size=decrease_size, lw=lw)\n",
    "\n",
    "\n",
    "def _plot_tarp_figure_2(ax, colors, fontsize, decrease_size, lw):\n",
    "    \"\"\"Plot TARP Figure 2: four posterior cases.\"\"\"\n",
    "    cases = [\n",
    "        ('correct', '$p(x)$', '-'),\n",
    "        ('overconfident', '$q(x)$', '.-'),\n",
    "        ('underconfident', '$r(x)$', '-'),\n",
    "        ('biased', '$s(x)$', '--'),\n",
    "    ]\n",
    "    \n",
    "    curves = []\n",
    "    for i, (case_name, label, ls) in enumerate(cases):\n",
    "        data = np.load(f'{PATH}/Tarp_Fig_2_Results/tarp_coverage_{case_name}_tarp_results.npz')\n",
    "        alpha = data['alpha_bootstrap']\n",
    "        ecp = data['ecp_bootstrap']\n",
    "        curves.append({\n",
    "            'alpha': alpha,\n",
    "            'mean': ecp.mean(axis=0),\n",
    "            'std': ecp.std(axis=0),\n",
    "            'label': label,\n",
    "            'color': colors[i],\n",
    "            'linestyle': ls,\n",
    "        })\n",
    "    \n",
    "    plot_coverage_curves(ax, curves, fontsize=fontsize, decrease_size=decrease_size, lw=lw)\n",
    "\n",
    "\n",
    "def _plot_model_misspecification(ax, colors, fontsize, decrease_size, lw):\n",
    "    \"\"\"Plot model misspecification results.\"\"\"\n",
    "    data = np.load(f'{PATH}/model_misspecification_tarp_data.npz')\n",
    "    \n",
    "    configs = [\n",
    "        ('EPL + 3 sources', 'EPL + 3 Sources'),\n",
    "        ('EPL + 1 sources', 'EPL + 1 Source'),\n",
    "        ('SIE + 3 sources', 'SIE + 3 Sources'),\n",
    "        ('SIE + 1 sources', 'SIE + 1 Source'),\n",
    "    ]\n",
    "    \n",
    "    curves = []\n",
    "    for i, (key_prefix, label) in enumerate(configs):\n",
    "        curves.append({\n",
    "            'alpha': data[f'{key_prefix}_alpha'],\n",
    "            'mean': data[f'{key_prefix}_ecp_mean'],\n",
    "            'std': data[f'{key_prefix}_ecp_std'],\n",
    "            'label': label,\n",
    "            'color': colors[i],\n",
    "        })\n",
    "    \n",
    "    plot_coverage_curves(ax, curves, fontsize=fontsize, decrease_size=decrease_size, lw=lw)\n",
    "\n",
    "\n",
    "def _plot_prior_noise_misspecification(ax, colors, fontsize, decrease_size, lw, line_alpha):\n",
    "    \"\"\"Plot prior and noise misspecification (lensing) results.\"\"\"\n",
    "    data = np.load(f'{PATH}/lens_exp/Lensing_tarp_coverage_data.npz')\n",
    "    \n",
    "    configs = [\n",
    "        (1, '$p_s(x)$, $\\\\sigma_{\\\\eta}=2$', '-'),\n",
    "        (2, '$p_s(x)$, $\\\\sigma_{\\\\eta}=4$', '.-'),\n",
    "        (3, '$p_m(x)$, $\\\\sigma_{\\\\eta}=2$', '-'),\n",
    "        (4, '$p_m(x)$, $\\\\sigma_{\\\\eta}=4$', '--'),\n",
    "    ]\n",
    "    \n",
    "    curves = []\n",
    "    for i, (num, label, ls) in enumerate(configs):\n",
    "        curves.append({\n",
    "            'alpha': data[f'posterior_{num}_alpha'],\n",
    "            'mean': data[f'posterior_{num}_ecp_mean'],\n",
    "            'std': data[f'posterior_{num}_ecp_std'],\n",
    "            'label': label,\n",
    "            'color': colors[i],\n",
    "            'linestyle': ls,\n",
    "            'line_alpha': 0.5,\n",
    "        })\n",
    "    \n",
    "    plot_coverage_curves(ax, curves, fontsize=fontsize, decrease_size=decrease_size, lw=lw)\n",
    "\n",
    "\n",
    "def _plot_conditional_distribution(ax, colors, fontsize, decrease_size, lw):\n",
    "    \"\"\"Plot conditional distribution model results.\"\"\"\n",
    "    data = np.load(f'{PATH}/TARP_Plots_Conditional_Model/Tarp_Result_Averaged_Data.npz')\n",
    "    \n",
    "    common_alpha = np.linspace(0, 1, 101)\n",
    "    common_alpha_ext = np.insert(common_alpha, 0, 0.0)\n",
    "    \n",
    "    cdm_mean = data['cdm_mean_ecp'].copy()\n",
    "    cdm_std = data['cdm_std_ecp'].copy()\n",
    "    # Apply correction from original code\n",
    "    cdm_mean[1] = 0.00547937\n",
    "    cdm_std[1] = 8.69164966e-05\n",
    "    \n",
    "    curves = [\n",
    "        {'alpha': common_alpha_ext, 'mean': cdm_mean, 'std': cdm_std,\n",
    "         'label': 'CDM', 'color': colors[0], 'std_multiplier': 3.0},\n",
    "        {'alpha': common_alpha_ext, 'mean': data['cvae_mean_ecp'], 'std': data['cvae_std_ecp'],\n",
    "         'label': 'CVAE', 'color': colors[1], 'std_multiplier': 3.0},\n",
    "    ]\n",
    "    \n",
    "    plot_coverage_curves(ax, curves, fontsize=fontsize, decrease_size=decrease_size, lw=lw,\n",
    "                        show_legend=True, legend_kwargs={'fontsize': 16, 'loc': 'upper left'})\n",
    "\n",
    "\n",
    "def _plot_inversebench(ax, experiment, methods, colors, fontsize, decrease_size, lw):\n",
    "    \"\"\"Plot InverseBench TARP results.\"\"\"\n",
    "    base_path = f'{PATH}/InverseBench/{experiment}'\n",
    "    \n",
    "    curves = []\n",
    "    for i, method in enumerate(methods):\n",
    "        try:\n",
    "            data = load_tarp_results(f'{base_path}/{method}_tarp_results.npz')\n",
    "            # Handle special label for piGDM\n",
    "            label = r'$\\pi\\text{GDM}$' if method == 'PiGDM' else method\n",
    "            curves.append({\n",
    "                'alpha': data['alpha'],\n",
    "                'mean': data['mean'],\n",
    "                'std': data['std'],\n",
    "                'label': label,\n",
    "                'color': colors[i % len(colors)],\n",
    "            })\n",
    "        except (FileNotFoundError, KeyError) as e:\n",
    "            print(f\"Warning: Could not load {method} data: {e}\")\n",
    "    \n",
    "    plot_coverage_curves(ax, curves, fontsize=fontsize, decrease_size=decrease_size, lw=lw,\n",
    "                        ylim=(-0.05, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776789b",
   "metadata": {},
   "source": [
    "## TARP Figure 2 Plots\n",
    "\n",
    "Figure 2: TARP coverage analysis showing biased, overconfident, underconfident, and correct posteriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ff320",
   "metadata": {
    "id": "991ff320"
   },
   "outputs": [],
   "source": [
    "FONTSIZE = 17\n",
    "LW = 1.5\n",
    "ALPHA = 0.9\n",
    "MARKERDGEWIDTH = 1.5\n",
    "MARKERSIZE = 8\n",
    "ELINEWIDTH = 2\n",
    "CAPSIZE = 10\n",
    "DECREASE_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARP Figure 2 Mira + Tarp plots\n",
    "\n",
    "cases = ['Correct', 'Overconfident', 'Underconfident', 'Biased']\n",
    "scores = [0.6624516844749451, 0.618563711643219, 0.6938722133636475, 0.5444898009300232]\n",
    "errors = [0.00697891553863883, 0.00876374077051878, 0.007383645512163639, 0.007584034465253353]\n",
    "\n",
    "L = 1000 # number of fiducials -> to be updt if needed\n",
    "\n",
    "fig1, axes1 = plt.subplots(nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(6, 6),\n",
    "    gridspec_kw={'hspace': 0.1}  # Try values between 0.2 and 0.5\n",
    ")\n",
    "left_ax1, right_ax1 = axes1\n",
    "\n",
    "plot_mira_scores(\n",
    "    x=np.arange(len(cases)),\n",
    "    y=scores,\n",
    "    L = L,\n",
    "    ax=left_ax1,\n",
    "    colors_hex=data_colors_hex,\n",
    "    yerr=errors,\n",
    "    xtick_labels=cases,\n",
    "    xtick_rotation=45,\n",
    "    # xlabel='Posteriors',\n",
    "    ylabel='Mira Score',\n",
    "    table_number='Table_1',\n",
    "    LR=False,\n",
    "    well_calibrated_color=WELL_CALIBRATED_COLOR,\n",
    "    poorly_calibrated_color=POORLY_CALIBRATED_COLOR,\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    ")\n",
    "plot_validation_result(\n",
    "    ax=right_ax1, \n",
    "    experiment_type='tarp_figure_2', \n",
    "    data_colors_hex=data_colors_hex,\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    ")\n",
    "\n",
    "fig1.set_constrained_layout(True)\n",
    "fig1.savefig('../plots/pdf/Tarp_Fig2_Pokie_Tarp.pdf')\n",
    "fig1.savefig('../plots/png/Tarp_Fig2_Pokie_Tarp.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a94730",
   "metadata": {},
   "source": [
    "## GMM Model Shift Analysis\n",
    "\n",
    "Distribution shift experiments with Gaussian Mixture Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473681f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "id": "d473681f",
    "outputId": "6a6982bc-1b1e-46f1-90d5-e1385ba99e0b"
   },
   "outputs": [],
   "source": [
    "model_shifts = [-6, -3, 0, 3, 6]\n",
    "scores = [0.5006, 0.5004, 0.6667, 0.5017, 0.5013]\n",
    "errors = [0.0137, 0.0141, 0.0102, 0.0120, 0.0134]\n",
    "L = 500 # number of fiducials -> to be updt if needed\n",
    "\n",
    "fig2, axes2 = plt.subplots(nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(6, 6),\n",
    "    gridspec_kw={'hspace': 0.1}  # Try values between 0.2 and 0.5\n",
    ")\n",
    "left_ax2, right_ax2 = axes2\n",
    "\n",
    "plot_mira_scores(\n",
    "    x=model_shifts,\n",
    "    y=scores,\n",
    "    L=L,\n",
    "    ax=left_ax2,\n",
    "    yerr=errors,\n",
    "    xtick_labels=model_shifts,\n",
    "    xlabel='Model Shift',\n",
    "    ylabel='Mira Score',\n",
    "    table_number='Table_GMM',\n",
    "    bbox_x=1.02,\n",
    "    bbox_y=0.90,\n",
    "    # title='Distribution Shift',\n",
    "    colors_hex=data_colors_hex,\n",
    "    well_calibrated_color=WELL_CALIBRATED_COLOR,\n",
    "    poorly_calibrated_color=POORLY_CALIBRATED_COLOR,\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    ")\n",
    "# fig2.suptitle('Distribution Shift', fontsize=60, fontweight='bold', y=1.00)  # adjust `y` as needed\n",
    "plot_validation_result(\n",
    "    ax=right_ax2,\n",
    "    experiment_type='pqmass',\n",
    "    data_colors_hex=data_colors_hex,\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    "    )\n",
    "\n",
    "fig2.set_constrained_layout(True)\n",
    "fig2.savefig('../plots/pdf/Distribution_Shift_Result.pdf')\n",
    "fig2.savefig('../plots/png/Distribution_Shift_Result.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3b78f",
   "metadata": {},
   "source": [
    "## Lensing Experiments\n",
    "\n",
    "Gravitational lensing posterior analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2bed5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "c7b2bed5",
    "outputId": "f5146fdb-1b15-4f33-aa2f-dc679fdc04c7"
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"EPL + 3\\nSersic Sources\",\n",
    "    \"SIE + 3\\nSersic Sources\",\n",
    "    \"EPL + 1\\nSersic Sources\",\n",
    "    \"SIE + 1\\nSersic Sources\"\n",
    "]\n",
    "scores = [0.6319946646690369, 0.5787630081176758, 0.5393556356430054, 0.5222544074058533]\n",
    "errors = [0.025168711319565773, 0.02674553170800209, 0.02755758911371231, 0.028337465599179268]\n",
    "L = 100\n",
    "\n",
    "FONTSIZE = 17\n",
    "LW = 1.5\n",
    "ALPHA = 0.9\n",
    "MARKERDGEWIDTH = 1.5\n",
    "MARKERSIZE = 8\n",
    "ELINEWIDTH = 2\n",
    "CAPSIZE = 10\n",
    "DECREASE_SIZE = 4\n",
    "\n",
    "\n",
    "fig4, axes4 = plt.subplots(nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(6, 6),\n",
    "    gridspec_kw={'hspace': 0.1}  # Try values between 0.2 and 0.5\n",
    ")\n",
    "left_ax4, right_ax4 = axes4\n",
    "\n",
    "plot_mira_scores(\n",
    "    x=range(len(models)),  # Use index for x-axis\n",
    "    y=scores,\n",
    "    L=L,\n",
    "    yerr=errors,\n",
    "    ax=left_ax4,\n",
    "    ylabel='Mira Score',\n",
    "    xtick_labels=models,\n",
    "    xtick_rotation=30,\n",
    "    table_number='Model_Misspecification',\n",
    "    colors_hex=data_colors_hex,\n",
    "    well_calibrated_color=WELL_CALIBRATED_COLOR,\n",
    "    poorly_calibrated_color=POORLY_CALIBRATED_COLOR,\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    "    # title='Model Misspecification',\n",
    ")\n",
    "# fig4.suptitle('Model Misspecification', fontsize=60, fontweight='bold', y=1.00)  # adjust `y` as needed\n",
    "plot_validation_result(ax=right_ax4, experiment_type='model_misspecification', data_colors_hex=data_colors_hex, lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,decrease_size=DECREASE_SIZE )\n",
    "\n",
    "fig4.set_constrained_layout(True)\n",
    "fig4.savefig('../plots/pdf/Model_Misspecification_Result.pdf')\n",
    "fig4.savefig('../plots/png/Model_Misspecification_Result.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84925d67",
   "metadata": {},
   "source": [
    "## InverseBench Experiments\n",
    "\n",
    "Inverse problems benchmark experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979d313",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "b979d313",
    "outputId": "fba6d11b-3538-426a-8637-77a86cb7036b"
   },
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    r\"$p_s(x)$\" + \"\\n\" + r\"$\\sigma_{\\eta}=2$\",\n",
    "    r\"$p_s(x)$\" + \"\\n\" + r\"$\\sigma_{\\eta}=0.5$\",\n",
    "    r\"$p_e(x)$\" + \"\\n\" + r\"$\\sigma_{\\eta}=2$\",\n",
    "    r\"$p_e(x)$\" + \"\\n\" + r\"$\\sigma_{\\eta}=0.5$\"\n",
    "]\n",
    "scores = [0.6442, 0.5783, 0.5298, 0.5056]\n",
    "errors = [0.0606, 0.0728, 0.0748, 0.0690]\n",
    "L = 16\n",
    "\n",
    "\n",
    "fig5, axes5 = plt.subplots(nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(6, 6),\n",
    "    gridspec_kw={'hspace': 0.1}  # Try values between 0.2 and 0.5\n",
    ")\n",
    "left_ax5, right_ax5 = axes5\n",
    "\n",
    "plot_mira_scores(\n",
    "    x=range(len(conditions)),  # Use index for x-axis\n",
    "    y=scores,\n",
    "    L=L,\n",
    "    yerr=errors,\n",
    "    ax=left_ax5,\n",
    "    xlabel='Prior and Noise Level',\n",
    "    ylabel='Mira Score',\n",
    "    xtick_labels=conditions,\n",
    "    xtick_rotation=0,\n",
    "    table_number='Table_Lensed_Images',\n",
    "    bbox_x = 1.02,\n",
    "    bbox_y = 0.87,\n",
    "    colors_hex=data_colors_hex,\n",
    "    well_calibrated_color=WELL_CALIBRATED_COLOR,\n",
    "    poorly_calibrated_color=POORLY_CALIBRATED_COLOR,\n",
    "    # title='Prior & Noise Misspecification',\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    ")\n",
    "# fig5.suptitle('Prior & Noise Misspecification', fontsize=60, fontweight='bold', y=1.00)  # adjust `y` as needed\n",
    "plot_validation_result(ax=right_ax5, experiment_type='prior_noise_misspecification', data_colors_hex=data_colors_hex,lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,decrease_size=DECREASE_SIZE )\n",
    "\n",
    "fig5.set_constrained_layout(True)\n",
    "fig5.savefig('../plots/pdf/Prior_and_Noise_Misspecification_Result.pdf')\n",
    "fig5.savefig('../plots/png/Prior_and_Noise_Misspecification_Result.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a5018",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7b3a5018",
    "outputId": "af0e3d47-c8db-4435-9bfe-cb85bd8eb63d"
   },
   "outputs": [],
   "source": [
    "# InverseBench: Black Hole Imaging\n",
    "\n",
    "models = [\n",
    "    \"DAPS\",\n",
    "    \"DiffPIR\",\n",
    "    \"DPS\",\n",
    "    \"PnPDM\",\n",
    "    \"REDDiff\"\n",
    "]\n",
    "\n",
    "scores = [0.51140004, 0.5089394, 0.51294947, 0.5096262  , 0.50591314 ]\n",
    "errors = [0.0294348, 0.02929415, 0.03200674, 0.02528337, 0.02917956]\n",
    "L=100\n",
    "\n",
    "fig6, axes6 = plt.subplots(nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(6, 6),\n",
    "    gridspec_kw={'hspace': 0.1}  # Try values between 0.2 and 0.5\n",
    ")\n",
    "left_ax6, right_ax6 = axes6\n",
    "\n",
    "plot_mira_scores(\n",
    "    x=range(len(models)),  # Use index for x-axis\n",
    "    y=scores,\n",
    "    yerr=errors,\n",
    "    L=L,\n",
    "    ax=left_ax6,\n",
    "    xlabel='Models',\n",
    "    ylabel='Mira Score',\n",
    "    xtick_labels=models,\n",
    "    xtick_rotation=0,\n",
    "    table_number='Table_IB_Black_Hole_Imaging',\n",
    "    bbox_x = 1.02,\n",
    "    bbox_y = 0.87,\n",
    "    colors_hex=data_colors_hex,\n",
    "    well_calibrated_color=WELL_CALIBRATED_COLOR,\n",
    "    poorly_calibrated_color=POORLY_CALIBRATED_COLOR,\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    "    # title='Prior & Noise Misspecification',\n",
    ")\n",
    "# fig6.suptitle('Prior & Noise Misspecification', fontsize=60, fontweight='bold', y=1.00)  # adjust `y` as needed\n",
    "plot_validation_result(ax=right_ax6, experiment_type='inversebench_black_hole', data_colors_hex=data_colors_hex,lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,decrease_size=DECREASE_SIZE )\n",
    "\n",
    "fig6.set_constrained_layout(True)\n",
    "fig6.savefig('../plots/pdf/InverseBench_BlackHoleImaging.pdf')\n",
    "fig6.savefig('../plots/png/InverseBench_BlackHoleImaging.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7fd30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b4c7fd30",
    "outputId": "c4185528-8bcf-49f8-b9a3-48f40c2b73f7"
   },
   "outputs": [],
   "source": [
    "# InverseBench: Compressed Sensing MRI\n",
    "\n",
    "models = [\n",
    "    \"DAPS\",\n",
    "    \"DiffPIR\",\n",
    "    \"DPS\",\n",
    "    \"PnPDM\",\n",
    "    \"REDDiff\"\n",
    "]\n",
    "scores = [0.51496667, 0.5051, 0.57823336, 0.5209, 0.51143336]\n",
    "errors = [0.10805649, 0.11640274, 0.11745473, 0.10246222, 0.11376356]\n",
    "\n",
    "L=6\n",
    "\n",
    "fig6, axes6 = plt.subplots(nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(6, 6),\n",
    "    gridspec_kw={'hspace': 0.1}  # Try values between 0.2 and 0.5\n",
    ")\n",
    "left_ax6, right_ax6 = axes6\n",
    "\n",
    "plot_mira_scores(\n",
    "    x=range(len(models)),  # Use index for x-axis\n",
    "    y=scores,\n",
    "    yerr=errors,\n",
    "    L=L,\n",
    "    ax=left_ax6,\n",
    "    xlabel='Models',\n",
    "    ylabel='Mira Score',\n",
    "    xtick_labels=models,\n",
    "    xtick_rotation=0,\n",
    "    table_number='Table_IB_Black_Hole_Imaging',\n",
    "    bbox_x = 1.02,\n",
    "    bbox_y = 0.87,\n",
    "    colors_hex=data_colors_hex,\n",
    "    well_calibrated_color=WELL_CALIBRATED_COLOR,\n",
    "    poorly_calibrated_color=POORLY_CALIBRATED_COLOR,\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE\n",
    "    # title='Prior & Noise Misspecification',\n",
    ")\n",
    "# fig6.suptitle('Prior & Noise Misspecification', fontsize=60, fontweight='bold', y=1.00)  # adjust `y` as needed\n",
    "plot_validation_result(ax=right_ax6, experiment_type='inversebench_mri', data_colors_hex=data_colors_hex,lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,decrease_size=DECREASE_SIZE )\n",
    "\n",
    "fig6.set_constrained_layout(True)\n",
    "fig6.savefig('../plots/pdf/InverseBench_CompressedSensingMRI.pdf')\n",
    "fig6.savefig('../plots/png/InverseBench_CompressedSensingMRI.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9e253",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0dd9e253",
    "outputId": "ba2ea682-6f94-429a-a3fc-dff67315d06f"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NOT INCLUDING THIS EXPERIMENT IN THE PAPER ANYMORE\n",
    "'''\n",
    "\n",
    "# # InverseBench: Linear Inverse Scattering\n",
    "# models = [\"DPS\", \"REDDiff\", \"DiffPIR\", \"PnPDM\", \"DAPS\", \"DDRM\", \"DDNM\", \"PiGDM\"]\n",
    "\n",
    "# scores = [0.5118748, 0.5107434, 0.50680405, 0.50886065, 0.5079172, 0.51027876, 0.50967073, 0.515402]\n",
    "# errors = [0.0030, 0.0029, 0.0028, 0.0029, 0.0035, 0.0024, 0.0033, 0.0028]\n",
    "# L =100\n",
    "\n",
    "# fig7, axes7 = plt.subplots(nrows=2,\n",
    "#     ncols=1,\n",
    "#     figsize=(6, 6),\n",
    "#     gridspec_kw={'hspace': 0.1}  # Try values between 0.2 and 0.5\n",
    "# )\n",
    "# left_ax7, right_ax7 = axes7\n",
    "\n",
    "# plot_mira_scores(\n",
    "#     x=range(len(models)),  # Use index for x-axis\n",
    "#     y=scores,\n",
    "#     yerr=errors,\n",
    "#     L=L,\n",
    "#     ax=left_ax7,\n",
    "#     xlabel='Models',\n",
    "#     ylabel='Mira Score',\n",
    "#     xtick_labels=models,\n",
    "#     xtick_rotation=45,\n",
    "#     table_number='Table_IB_Black_Hole_Imaging',\n",
    "#     bbox_x = 1.02,\n",
    "#     bbox_y = 0.87,\n",
    "#     colors_hex=data_colors_hex,\n",
    "#     well_calibrated_color=WELL_CALIBRATED_COLOR,\n",
    "#     poorly_calibrated_color=POORLY_CALIBRATED_COLOR,\n",
    "#     lw=LW,\n",
    "#     fontsize=FONTSIZE,\n",
    "#     alpha=ALPHA,\n",
    "#,\n",
    "#,\n",
    "#,\n",
    "#,\n",
    "#     decrease_size=DECREASE_SIZE\n",
    "#     # title='Prior & Noise Misspecification',\n",
    "# )\n",
    "# # fig7.suptitle('Prior & Noise Misspecification', fontsize=60, fontweight='bold', y=1.00)  # adjust `y` as needed\n",
    "# plot_validation_result(ax=right_ax7, experiment_type='inversebench_scattering', data_colors_hex=data_colors_hex,lw=LW,\n",
    "#     fontsize=FONTSIZE,\n",
    "#     alpha=ALPHA,\n",
    "#,\n",
    "#,\n",
    "#,\n",
    "#,decrease_size=DECREASE_SIZE )\n",
    "\n",
    "# fig7.set_constrained_layout(True)\n",
    "# fig7.savefig(../plots/pdf/InverseBench_LIS.pdf')\n",
    "# fig7.savefig(../plots/png/InverseBench_LIS.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a0dbc",
   "metadata": {},
   "source": [
    "## Mira Plotting Functions\n",
    "\n",
    "Functions for plotting Mira sensitivity analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96781e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_mira_alone is now defined in the consolidated plotting functions cell above\n",
    "# It is aliased to plot_mira_scores for backward compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72981858",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE = 22\n",
    "LW = 1.5\n",
    "ALPHA = 0.9\n",
    "MARKERDGEWIDTH = 1.5\n",
    "MARKERSIZE = 10\n",
    "ELINEWIDTH = 2\n",
    "CAPSIZE = 10\n",
    "DECREASE_SIZE = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6ea2c",
   "metadata": {},
   "source": [
    "## Mira Sensitivity Analysis\n",
    "\n",
    "Sensitivity analysis plots for the Mira method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5facb058",
   "metadata": {},
   "source": [
    "# MISSING LEGEND!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff6991f",
   "metadata": {
    "id": "dff6991f"
   },
   "outputs": [],
   "source": [
    "# Sensitivity Mira Result\n",
    "\n",
    "lr_10_posteriors = (\n",
    "    [0.6655, 0.6125, 0.5652, 0.5634, 0.5676, 0.5545],\n",
    "    [0.0828, 0.0779, 0.0823, 0.0889, 0.0814, 0.0971]\n",
    ")\n",
    "\n",
    "lr_50_posteriors = (\n",
    "    [0.6710, 0.6421, 0.5731, 0.5623, 0.5554, 0.5499],\n",
    "    [0.0362, 0.0410, 0.0376, 0.0366, 0.0393, 0.0442]\n",
    ")\n",
    "\n",
    "lr_100_posteriors = (\n",
    "    [0.6652, 0.6380, 0.5683, 0.5620, 0.5572, 0.5493],\n",
    "    [0.0226, 0.0257, 0.0277, 0.0282, 0.0296, 0.0292]\n",
    ")\n",
    "\n",
    "lr_500_posteriors = (\n",
    "    [0.6650, 0.6414, 0.5677, 0.5595, 0.5532, 0.5530],\n",
    "    [0.0120, 0.0114, 0.0129, 0.0118, 0.0130, 0.0136]\n",
    ")\n",
    "\n",
    "lr_1000_posteriors = (\n",
    "    [0.6665, 0.6427, 0.5671, 0.5581, 0.5542, 0.5527],\n",
    "    [0.0075, 0.0082, 0.0091, 0.0105, 0.0090, 0.0087]\n",
    ")\n",
    "\n",
    "# lr_5000_posteriors = (\n",
    "#     [0.6643, 0.6409, 0.5670, 0.5590, 0.5549, 0.5519],\n",
    "#     [0.0016, 0.0021, 0.0010, 0.0010, 0.0012, 0.0009]\n",
    "# )\n",
    "\n",
    "noise_levels = [0.001, 0.010, 0.100, 0.150, 0.200, 0.250]\n",
    "\n",
    "posteriors = {\n",
    "    \"LR=10\": lr_10_posteriors,\n",
    "    \"LR=50\": lr_50_posteriors,\n",
    "    \"LR=100\": lr_100_posteriors,\n",
    "    \"LR=500\": lr_500_posteriors,\n",
    "    \"LR=1000\": lr_1000_posteriors,\n",
    "    # \"LR=5000\": lr_5000_posteriors\n",
    "}\n",
    "\n",
    "# Make one figure\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Call your function for each metric\n",
    "for i, (num_fiducials, (scores, errors)) in enumerate(posteriors.items()):\n",
    "    print(f\"Plotting: {num_fiducials} with scores: {scores} and errors: {errors}\")\n",
    "    plot_mira_alone(\n",
    "        x=np.arange(len(noise_levels)),\n",
    "        y=scores,\n",
    "        yerr=errors,\n",
    "        ax=ax,  # same axis each time\n",
    "        colors_hex=[data_colors_hex[i % len(data_colors_hex)]],  # pick 1 color\n",
    "        xtick_labels=[str(nl) for nl in noise_levels],\n",
    "        xtick_rotation=45,\n",
    "        xlabel=\"Noise Level\",\n",
    "        ylabel=\"Mira Score\",\n",
    "        table_number=f\"Table_{i+1}\",\n",
    "        model_name=num_fiducials,\n",
    "        draw_fill=(i == 0),\n",
    "        lw=LW,\n",
    "        L=1000,\n",
    "        fontsize=FONTSIZE,\n",
    "        alpha=ALPHA,\n",
    "        decrease_size=DECREASE_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "fig.set_constrained_layout(True)\n",
    "fig.savefig(\"../plots/pdf/LR_Sensitivity_Pokie_Result.pdf\")\n",
    "fig.savefig(\"../plots/png/LR_Sensitivity_Pokie_Result.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c7a0f",
   "metadata": {},
   "source": [
    "## Mira Distance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52097a8",
   "metadata": {
    "id": "e52097a8"
   },
   "outputs": [],
   "source": [
    "# Distance Mira Result\n",
    "noise_levels = [0.001, 0.010, 0.100, 0.150, 0.200, 0.250]\n",
    "\n",
    "metrics = {\n",
    "    \"L2\": (\n",
    "        [0.6642, 0.6417, 0.5658, 0.5577, 0.5535, 0.5506],\n",
    "        [0.0038, 0.0034, 0.0042, 0.0048, 0.0040, 0.0042]\n",
    "    ),\n",
    "    \"L1\": (\n",
    "        [0.6633, 0.6417, 0.5768, 0.5689, 0.5626, 0.5589],\n",
    "        [0.0033, 0.0036, 0.0038, 0.0043, 0.0039, 0.0043]\n",
    "    ),\n",
    "    \"Chebyshev\": (\n",
    "        [0.6635, 0.6426, 0.5624, 0.5525, 0.5485, 0.5464],\n",
    "        [0.0036, 0.0039, 0.0038, 0.0039, 0.0041, 0.0042]\n",
    "    ),\n",
    "    \"Cosine\": (\n",
    "        [0.6609, 0.6476, 0.6086, 0.5987, 0.5918, 0.5858],\n",
    "        [0.0038, 0.0034, 0.0034, 0.0040, 0.0036, 0.0036]\n",
    "    ),\n",
    "    \"Minkowski\": (\n",
    "        [0.6634, 0.6399, 0.5628, 0.5534, 0.5495, 0.5476],\n",
    "        [0.0040, 0.0036, 0.0038, 0.0044, 0.0039, 0.0039]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Make one figure\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Call your function for each metric\n",
    "for i, (metric_name, (scores, errors)) in enumerate(metrics.items()):\n",
    "    print(f\"Plotting metric: {metric_name} with scores: {scores} and errors: {errors}\")\n",
    "    plot_mira_alone(\n",
    "        x=np.arange(len(noise_levels)),\n",
    "        y=scores,\n",
    "        yerr=errors,\n",
    "        ax=ax,  # same axis each time\n",
    "        colors_hex=[data_colors_hex[i % len(data_colors_hex)]],  # pick 1 color\n",
    "        xtick_labels=[str(nl) for nl in noise_levels],\n",
    "        xtick_rotation=45,\n",
    "        draw_fill=(i == 0),\n",
    "        xlabel=\"Noise Level\",\n",
    "        ylabel=\"Mira Score\",\n",
    "        table_number=f\"Table_{i+1}\",\n",
    "        model_name=metric_name,  # Pass metric name for legend\n",
    "        lw=LW,\n",
    "        L=5000,\n",
    "        fontsize=FONTSIZE,\n",
    "        alpha=ALPHA,\n",
    "        decrease_size=DECREASE_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "fig.set_constrained_layout(True)\n",
    "fig.savefig(\"../plots/pdf/Distance_Pokie_Result.pdf\")\n",
    "fig.savefig(\"../plots/png/Distance_Pokie_Result.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0e831",
   "metadata": {},
   "source": [
    "## Mira Distribution Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96028669",
   "metadata": {
    "id": "96028669"
   },
   "outputs": [],
   "source": [
    "# Distribution Mira Result\n",
    "# Table Distribution_Choice\n",
    "noise_levels = [0.001, 0.010, 0.100, 0.150, 0.200, 0.250]\n",
    "\n",
    "# Scores and 68% CI errors for each center distribution\n",
    "distributions = {\n",
    "    \"Uniform\": (\n",
    "        [0.6638, 0.6397, 0.5652, 0.5578, 0.5526, 0.5496],\n",
    "        [0.0028, 0.0034, 0.0039, 0.0037, 0.0038, 0.0041]\n",
    "    ),\n",
    "    \"Normal\": (\n",
    "        [0.6633, 0.6395, 0.5525, 0.5405, 0.5348, 0.5301],\n",
    "        [0.0034, 0.0034, 0.0040, 0.0040, 0.0040, 0.0045]\n",
    "    ),\n",
    "    \"Beta(2,5)\": (\n",
    "        [0.6646, 0.6444, 0.5546, 0.5396, 0.5282, 0.5234],\n",
    "        [0.0034, 0.0037, 0.0041, 0.0038, 0.0039, 0.0044]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Make one figure\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Call your function for each distribution\n",
    "for i, (distribution_name, (scores, errors)) in enumerate(distributions.items()):\n",
    "    print(f\"Plotting distribution: {distribution_name} with scores: {scores} and errors: {errors}\")\n",
    "    plot_mira_alone(\n",
    "        x=np.arange(len(noise_levels)),\n",
    "        y=scores,\n",
    "        yerr=errors,\n",
    "        ax=ax,  # same axis each time\n",
    "        colors_hex=[data_colors_hex[i % len(data_colors_hex)]],  # pick 1 color\n",
    "        xtick_labels=[str(nl) for nl in noise_levels],\n",
    "        xtick_rotation=45,\n",
    "        xlabel=\"Noise Level\",\n",
    "        ylabel=\"Mira Score\",\n",
    "        table_number=f\"Table_{i+1}\",\n",
    "        draw_fill=(i == 0),\n",
    "        model_name=distribution_name,  # Pass distribution name for legend\n",
    "        lw=LW,\n",
    "        L=5000,\n",
    "        fontsize=FONTSIZE,\n",
    "        alpha=ALPHA,\n",
    "        decrease_size=DECREASE_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "fig.set_constrained_layout(True)\n",
    "fig.savefig(\"../plots/pdf/Center_Distribution_Pokie_Result.pdf\")\n",
    "fig.savefig(\"../plots/png/Center_Distribution_Pokie_Result.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdca89b",
   "metadata": {},
   "source": [
    "## Mira Ellipse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ellipse Mira Result\n",
    "# Table Region_Choice (Ellipse Stretch Configurations)\n",
    "noise_levels = [0.001, 0.010, 0.100, 0.150, 0.200, 0.250]\n",
    "\n",
    "# Scores and errors by ellipse stretch configuration\n",
    "ellipse_configs = {\n",
    "    \"(1.0, 2.0)\": (\n",
    "        [0.6669, 0.6520, 0.5801, 0.5652, 0.5566, 0.5492],\n",
    "        [0.0038, 0.0051, 0.0055, 0.0051, 0.0045, 0.0057]\n",
    "    ),\n",
    "    \"(0.5, 1.5)\": (\n",
    "        [0.6656, 0.6550, 0.5834, 0.5650, 0.5527, 0.5442],\n",
    "        [0.0044, 0.0040, 0.0044, 0.0045, 0.0049, 0.0051]\n",
    "    ),\n",
    "    \"(1.5, 1.0)\": (\n",
    "        [0.6629, 0.6376, 0.5521, 0.5416, 0.5374, 0.5351],\n",
    "        [0.0048, 0.0051, 0.0050, 0.0058, 0.0056, 0.0044]\n",
    "    ),\n",
    "    \"(2.0, 0.5)\": (\n",
    "        [0.6627, 0.6332, 0.5354, 0.5276, 0.5258, 0.5239],\n",
    "        [0.0044, 0.0051, 0.0053, 0.0055, 0.0054, 0.0058]\n",
    "    ),\n",
    "    \"(0.8, 1.2)\": (\n",
    "        [0.6655, 0.6481, 0.5766, 0.5654, 0.5595, 0.5545],\n",
    "        [0.0046, 0.0041, 0.0048, 0.0051, 0.0047, 0.0042]\n",
    "    )\n",
    "}\n",
    "\n",
    "# Make one figure\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Call your function for each distribution\n",
    "for i, (shape_size, (scores, errors)) in enumerate(ellipse_configs.items()):\n",
    "    print(f\"Plotting shape size: {shape_size} with scores: {scores} and errors: {errors}\")\n",
    "    plot_mira_alone(\n",
    "        x=np.arange(len(noise_levels)),\n",
    "        y=scores,\n",
    "        yerr=errors,\n",
    "        ax=ax,  # same axis each time\n",
    "        colors_hex=[data_colors_hex[i % len(data_colors_hex)]],  # pick 1 color\n",
    "        xtick_labels=[str(nl) for nl in noise_levels],\n",
    "        xtick_rotation=45,\n",
    "        xlabel=\"Noise Level\",\n",
    "        ylabel=\"Mira Score\",\n",
    "        table_number=f\"Table_{i+1}\",\n",
    "        model_name=shape_size,  # Pass shape size for legend\n",
    "        LR=False,\n",
    "        draw_fill=(i == 0),\n",
    "        lw=LW,\n",
    "        L=3000,\n",
    "        fontsize=FONTSIZE,\n",
    "        alpha=ALPHA,\n",
    "        decrease_size=DECREASE_SIZE\n",
    "    )\n",
    "\n",
    "\n",
    "fig.set_constrained_layout(True)\n",
    "fig.savefig(\"../plots/pdf/Shape_Size_Pokie_Result.pdf\")\n",
    "fig.savefig(\"../plots/png/Shape_Size_Pokie_Result.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494263d",
   "metadata": {},
   "source": [
    "## Sensitivity Aggregated Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12021cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import std\n",
    "\n",
    "\n",
    "def plot_all_mira_experiments(\n",
    "    dimensions, \n",
    "    hyperspheres, \n",
    "    posterior_samples,\n",
    "    L,\n",
    "    shifts=None,\n",
    "    colors_hex=None,\n",
    "    lw=5,\n",
    "    legend_fontsize=8,\n",
    "    well_calibrated_color=None,\n",
    "    poorly_calibrated_color=None,\n",
    "    underconfidence_color=None,\n",
    "    save_path=None,\n",
    "    fontsize=20,\n",
    "    markersize=2,\n",
    "    markeredgewidth=2,\n",
    "    elinewidth=2,\n",
    "    alpha=0.5,\n",
    "    capsize=10,\n",
    "    decrease_size=2,\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import matplotlib as mpl\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    x_label_font_size = fontsize\n",
    "    y_label_font_size = fontsize\n",
    "    tick_label_size = fontsize - decrease_size\n",
    "    legend_font_size = fontsize - decrease_size\n",
    "\n",
    "    if shifts is None:\n",
    "        shifts = [-6, -3, 0, 3, 6]\n",
    "    if colors_hex is None:\n",
    "        # Fallback color set\n",
    "        colors_hex = get_diverse_icefire_colors(10)[1]\n",
    "\n",
    "    # fig, axs = plt.subplots(2, 2, figsize=(7, 7))\n",
    "    # axs = axs.flatten()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    # Helper to plot each group\n",
    "    def plot_group(ax, data, title, xlabel):\n",
    "        ax.grid(False)\n",
    "        for i, (label, values) in enumerate(data.items()):\n",
    "            ax.errorbar(\n",
    "                shifts,\n",
    "                values[\"scores\"],\n",
    "                yerr=values[\"errors\"],\n",
    "                fmt='o',\n",
    "                capsize=capsize,\n",
    "                color=colors_hex[i % len(colors_hex)],\n",
    "                markersize=markersize,\n",
    "                alpha=1.0,\n",
    "                markeredgewidth=markeredgewidth,\n",
    "                elinewidth=elinewidth,\n",
    "                label=label,\n",
    "            )\n",
    "        ax.axhline(1/2, color='gray', linestyle='--', alpha = 1.0, lw=1.5, label='Poorly Calibrated')\n",
    "\n",
    "        # ax.axhline((1/2 + 1/np.sqrt(12)), color='gray', linestyle='--', alpha = 1.0, lw=1.5, label='Underconfident')\n",
    "\n",
    "\n",
    "        # Titles, labels, formatting\n",
    "        ax.set_title(title, fontsize=25, fontweight='bold')\n",
    "        ax.set_xlabel(xlabel, fontsize=x_label_font_size)\n",
    "        # If ax is the leftmost, set y label\n",
    "        if ax == axs[0]:\n",
    "            ax.set_ylabel(\"Mira Score\", fontsize=y_label_font_size)\n",
    "        ax.tick_params(axis='x', labelsize=tick_label_size)\n",
    "        ax.tick_params(axis='y', labelsize=tick_label_size)\n",
    "\n",
    "        # Set x ticks to shifts\n",
    "        ax.set_xticks(shifts)\n",
    "        formatter = mpl.ticker.FormatStrFormatter('%.2f')\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "        # ax.set_ylim(0.48, 0.68)\n",
    "\n",
    "        # Deduplicated legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = OrderedDict(zip(labels, handles))\n",
    "        if 'Well Calibrated' in by_label:\n",
    "            by_label.pop('Well Calibrated')\n",
    "        if 'Poorly Calibrated' in by_label:\n",
    "            by_label.pop('Poorly Calibrated')\n",
    "        if 'Underconfident' in by_label:\n",
    "            by_label.pop('Underconfident')\n",
    "        ax.legend(\n",
    "            by_label.values(),\n",
    "            by_label.keys(),\n",
    "            fontsize=legend_fontsize,\n",
    "            loc=\"upper right\"\n",
    "        )\n",
    "\n",
    "        # Calibration lines\n",
    "        variance = (1/18)/L\n",
    "        std = np.sqrt(variance)\n",
    "        ax.axhline(2/3, color='black', linestyle='--', alpha = 1.0, lw=1.5, label='Well Calibrated')\n",
    "        support = np.linspace(-7, 7, 100)\n",
    "        ax.fill_between(support, 2/3 - std, 2/3 + std, alpha=0.2, color='black')\n",
    "        ax.set_xlim(-7, 7)\n",
    "\n",
    "    # Apply to each subplot\n",
    "    plot_group(axs[0], dimensions, \"Varying Dimensions\", \"Shift Value\")\n",
    "    plot_group(axs[1], hyperspheres, \"Varying Number of Regions\", \"Shift Value\")\n",
    "    plot_group(axs[2], posterior_samples, \"Varying Posterior Samples\", \"Shift Value\")\n",
    "    # Decrease plot title size\n",
    "    for ax in axs:\n",
    "        ax.title.set_size(17)\n",
    "    # axs[3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ba069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity Test (2 x 2 plot with lower right turned off) Top Left: Dimensions Test, Top Right: L, Bottom Left: Num of Samples\n",
    "\n",
    "dimensions = {\n",
    "    \"2D\": {\n",
    "        \"scores\": [0.6045, 0.6483, 0.6669, 0.6481, 0.5984],\n",
    "        \"errors\": [0.0038, 0.0033, 0.0031, 0.0030, 0.0040]\n",
    "    },\n",
    "    \"5D\": {\n",
    "        \"scores\": [0.5526, 0.6315, 0.6671, 0.6228, 0.5389],\n",
    "        \"errors\": [0.0050, 0.0037, 0.0035, 0.0039, 0.0045]\n",
    "    },\n",
    "    \"10D\": {\n",
    "        \"scores\": [0.5233, 0.6171, 0.6670, 0.6124, 0.5176],\n",
    "        \"errors\": [0.0041, 0.0040, 0.0037, 0.0039, 0.0044]\n",
    "    },\n",
    "    \"100D\": {\n",
    "        \"scores\": [0.5000, 0.5132, 0.6669, 0.5113, 0.5002],\n",
    "        \"errors\": [0.0042, 0.0042, 0.0034, 0.0038, 0.0040]\n",
    "    }\n",
    "}\n",
    "\n",
    "hyperspheres = {\n",
    "    \"1 run\": {\n",
    "        \"scores\": [0.50174594, 0.5056617, 0.6693001, 0.50787807, 0.50258905],\n",
    "        \"errors\": [0.01206928, 0.01407796, 0.00984546, 0.01173354, 0.01393633]\n",
    "    },\n",
    "    \"20 runs\": {\n",
    "        \"scores\": [0.49978226, 0.51480174, 0.66691643, 0.5067856, 0.5003773],\n",
    "        \"errors\": [0.01241044, 0.01214088, 0.00971929, 0.01128353, 0.01315701]\n",
    "    },\n",
    "    \"50 runs\": {\n",
    "        \"scores\": [0.5013516, 0.5108235, 0.66729254, 0.5139341, 0.5020315],\n",
    "        \"errors\": [0.01271933, 0.01252874, 0.01006315, 0.01246938, 0.01378876]\n",
    "    },\n",
    "    \"100 runs\": {\n",
    "        \"scores\": [0.5016635, 0.51724625, 0.666212, 0.51095235, 0.50109875],\n",
    "        \"errors\": [0.01265017, 0.01357112, 0.011236, 0.01181128, 0.01200862]\n",
    "    }\n",
    "}\n",
    "\n",
    "posterior_samples = {\n",
    "    \"10 samples\": {\n",
    "        \"scores\": [0.551524, 0.558326, 0.700476, 0.561078, 0.551656],\n",
    "        \"errors\": [0.01227844, 0.01295106, 0.01041854, 0.01242701, 0.01262283]\n",
    "    },\n",
    "    \"50 samples\": {\n",
    "        \"scores\": [0.5068244, 0.52390444, 0.6718412, 0.521318, 0.50925756],\n",
    "        \"errors\": [0.01214749, 0.01329519, 0.01028553, 0.01222892, 0.01169688]\n",
    "    },\n",
    "    \"100 samples\": {\n",
    "        \"scores\": [0.5075212, 0.5151786, 0.6719145, 0.51890856, 0.504944],\n",
    "        \"errors\": [0.01285653, 0.01281209, 0.01091054, 0.01374135, 0.0159563]\n",
    "    },\n",
    "    # \"200 samples\": {\n",
    "    #     \"scores\": [0.5036858, 0.51340437, 0.6679275, 0.5200728, 0.5014128],\n",
    "    #     \"errors\": [0.01274271, 0.00955724, 0.01060478, 0.013953, 0.01276546]\n",
    "    # },\n",
    "    \"300 samples\": {\n",
    "        \"scores\": [0.5016408, 0.5107455, 0.6657693, 0.50997925, 0.5033823],\n",
    "        \"errors\": [0.01237438, 0.01296766, 0.01058149, 0.01192634, 0.0130619]\n",
    "    },\n",
    "    \"400 samples\": {\n",
    "        \"scores\": [0.50039786, 0.5123267, 0.6688564, 0.5128226, 0.5022506],\n",
    "        \"errors\": [0.01289913, 0.01267484, 0.00940202, 0.01235659, 0.01377634]\n",
    "    },\n",
    "    # \"500 samples\": {\n",
    "    #     \"scores\": [0.5017785, 0.5091051, 0.66844094, 0.5131277, 0.49969608],\n",
    "    #     \"errors\": [0.01258485, 0.01200053, 0.01023337, 0.01384445, 0.01199949]\n",
    "    # }\n",
    "}\n",
    "\n",
    "'''\n",
    "Colors\n",
    "Legend\n",
    "Size of Markers\n",
    "\n",
    "'''\n",
    "FONTSIZE = 22\n",
    "LW = 1.5\n",
    "ALPHA = 0.9\n",
    "MARKERDGEWIDTH = 1.5\n",
    "MARKERSIZE = 5\n",
    "ELINEWIDTH = 2\n",
    "CAPSIZE = 10\n",
    "DECREASE_SIZE = 4\n",
    "\n",
    "model_shifts = [-6, -3, 0, 3, 6]\n",
    "\n",
    "plot_all_mira_experiments(\n",
    "    dimensions=dimensions,\n",
    "    hyperspheres=hyperspheres,\n",
    "    posterior_samples=posterior_samples,\n",
    "    colors_hex=data_colors_hex, \n",
    "    lw=LW,\n",
    "    L=1000,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE,\n",
    "    save_path=\"../plots/pdf/Sensitivity_All_Experiments.pdf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba158ea",
   "metadata": {},
   "source": [
    "## Conditional Generative Model Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d86d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9484245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mira_curve(\n",
    "    ax,\n",
    "    epochs,\n",
    "    scores,\n",
    "    *,\n",
    "    label,\n",
    "    color,\n",
    "    L=1000,\n",
    "    lw=1.5,\n",
    "    alpha=0.9,\n",
    "    markersize=6,\n",
    "    markeredgewidth=1.5,\n",
    "    eline_alpha=0.15,\n",
    "    fontsize=15,\n",
    "    show_reference=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a single MIRA curve with error band and calibration references.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        Axis to plot on\n",
    "    epochs : 1D np.ndarray\n",
    "        Epoch numbers\n",
    "    scores : 1D np.ndarray\n",
    "        Average MIRA scores\n",
    "    label : str\n",
    "        Label for legend\n",
    "    color : str\n",
    "        Line/marker color\n",
    "    L : int\n",
    "        Number of fiducials (controls error size)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Error model (your theoretical bound)\n",
    "    std = np.sqrt((1 / 18) / L)\n",
    "\n",
    "    # --- Main curve\n",
    "    ax.plot(\n",
    "        epochs,\n",
    "        scores,\n",
    "        marker='o',\n",
    "        lw=lw,\n",
    "        color=color,\n",
    "        alpha=alpha,\n",
    "        markersize=markersize,\n",
    "        markeredgewidth=markeredgewidth,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "    # --- Error band\n",
    "    ax.fill_between(\n",
    "        epochs,\n",
    "        scores - std,\n",
    "        scores + std,\n",
    "        color=color,\n",
    "        alpha=eline_alpha,\n",
    "        linewidth=0,\n",
    "    )\n",
    "\n",
    "    # --- Reference calibration lines\n",
    "    if show_reference:\n",
    "        ax.axhline(0.5, color='gray', linestyle='--', lw=lw, alpha = 1.0)\n",
    "        ax.axhline(2/3, color='black', linestyle='--', lw=lw, alpha = 1.0)\n",
    "        # ax.axhline(0.5 + 1/np.sqrt(12), color='gray', linestyle='--', lw=lw)\n",
    "        variance = (1/18)/1000\n",
    "        std = np.sqrt(variance)\n",
    "        support = epochs\n",
    "        ax.fill_between(support, 2/3 - std, 2/3 + std, alpha=0.2, color='black')\n",
    "\n",
    "    # --- Axis formatting\n",
    "    ax.set_xlim(epochs[0] - 0.5, epochs[-1] + 0.5)\n",
    "    ax.set_ylabel(\"MIRA Score\", fontsize=fontsize)\n",
    "    ax.tick_params(axis='both', labelsize=fontsize - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5febb8",
   "metadata": {},
   "source": [
    "## Training Curves\n",
    "\n",
    "Functions for plotting training curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4623385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "def plot_mira_training_curves(\n",
    "    ax,\n",
    "    cache,\n",
    "    models,\n",
    "    colors_hex,\n",
    "    L=100,\n",
    "    ylabel='MIRA Score',\n",
    "    xlabel='Epoch',\n",
    "    title=None,\n",
    "    lw=1.5,\n",
    "    fontsize=20,\n",
    "    markersize_trail=3,\n",
    "    markersize_final=10,\n",
    "    markeredgewidth=1.5,\n",
    "    alpha_trail=0.3,\n",
    "    alpha_final=1.0,\n",
    "    decrease_size=2,\n",
    "    well_calibrated_line=True,\n",
    "    poorly_calibrated_line=True,\n",
    "    conditional_distribution=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot MIRA score as a function of training epoch with faded training history\n",
    "    and bold final points to emphasize final results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes to plot on\n",
    "    cache : dict-like\n",
    "        Data cache containing '{model}_epochs' and '{model}_scores' arrays\n",
    "    models : list of str\n",
    "        Model names to plot (e.g., [\"CDM V1\", \"CVAE V1\"])\n",
    "    colors_hex : list of str\n",
    "        Colors for each model\n",
    "    L : int\n",
    "        Number of samples (for computing well-calibrated uncertainty band)\n",
    "    ylabel : str\n",
    "        Y-axis label\n",
    "    xlabel : str\n",
    "        X-axis label\n",
    "    title : str, optional\n",
    "        Plot title\n",
    "    lw : float\n",
    "        Line width for training curves\n",
    "    fontsize : int\n",
    "        Base font size\n",
    "    markersize_trail : float\n",
    "        Marker size for faded training history\n",
    "    markersize_final : float\n",
    "        Marker size for final (bold) points\n",
    "    markeredgewidth : float\n",
    "        Edge width for final markers\n",
    "    alpha_trail : float\n",
    "        Opacity for training history (faded)\n",
    "    alpha_final : float\n",
    "        Opacity for final points (bold)\n",
    "    decrease_size : int\n",
    "        Amount to decrease font size for ticks/legend\n",
    "    well_calibrated_line : bool\n",
    "        Whether to show the well-calibrated reference line at 2/3\n",
    "    poorly_calibrated_line : bool\n",
    "        Whether to show the poorly-calibrated reference line at 1/2\n",
    "    \"\"\"\n",
    "    \n",
    "    tick_label_size = fontsize - decrease_size\n",
    "    legend_font_size = fontsize - decrease_size\n",
    "    \n",
    "    ax.grid(False)\n",
    "    \n",
    "    # Track x-range for fill_between\n",
    "    all_epochs = []\n",
    "    x_min = 1\n",
    "    x_max = 500\n",
    "    # Reference lines\n",
    "    if poorly_calibrated_line:\n",
    "        ax.axhline(1/2, color='gray', linestyle='--', alpha=1.0, lw=lw)\n",
    "    \n",
    "    if well_calibrated_line:\n",
    "        ax.axhline(2/3, color='black', linestyle='--', alpha=1.0, lw=lw)\n",
    "        # Uncertainty band\n",
    "        variance = (1/18) / L\n",
    "        std = np.sqrt(variance)\n",
    "        \n",
    "        # axhspan automatically spans the full x-axis, regardless of scale\n",
    "        ax.axhspan(2/3 - std, 2/3 + std, alpha=0.2, color='black')\n",
    "    \n",
    "    for model, color in zip(models, colors_hex):\n",
    "        epochs = cache[f\"{model}_epochs\"]\n",
    "        scores = cache[f\"{model}_scores\"]\n",
    "        all_epochs.extend(epochs)\n",
    "        \n",
    "        # Plot the training trajectory (faded)\n",
    "        ax.plot(\n",
    "            epochs[:-1], scores[:-1],\n",
    "            color=color,\n",
    "            alpha=alpha_trail,\n",
    "            marker='o',\n",
    "            markersize=markersize_trail,\n",
    "            linewidth=lw\n",
    "        )\n",
    "        \n",
    "        # Connect last faded point to final point (faded line)\n",
    "        ax.plot(\n",
    "            epochs[-2:], scores[-2:],\n",
    "            color=color,\n",
    "            alpha=alpha_trail,\n",
    "            linewidth=lw\n",
    "        )\n",
    "        \n",
    "        # Plot the final point (bold) with label\n",
    "        ax.plot(\n",
    "            epochs[-1], scores[-1],\n",
    "            color=color,\n",
    "            alpha=alpha_final,\n",
    "            marker='o',\n",
    "            markersize=markersize_final,\n",
    "            markeredgecolor='white',\n",
    "            markeredgewidth=markeredgewidth,\n",
    "            label=f\"{model[:-3]}\", # the model name minus the last 3 characters\n",
    "            linestyle='None'\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=fontsize, fontweight='bold')\n",
    "    ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    ax.set_ylabel(ylabel, fontsize=fontsize)\n",
    "    ax.tick_params(axis='x', labelsize=15, colors='black')\n",
    "    ax.tick_params(axis='y', labelsize=tick_label_size, colors='black')\n",
    "    \n",
    "    # Format y-axis to two decimal places\n",
    "    formatter = mpl.ticker.FormatStrFormatter('%.2f')\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    \n",
    "    # ax.legend(fontsize=legend_font_size, loc='upper left')\n",
    "    # Log the x axis\n",
    "    ax.set_xscale('log')\n",
    "    return ax\n",
    "\n",
    "models = [\"Conditional\\nDiffusion Model\", \"Conditional\\nVAE\"]\n",
    "\n",
    "scores = [0.6599, 0.5748]\n",
    "errors = [0.0248, 0.0276]\n",
    "\n",
    "L =100\n",
    "\n",
    "cache = np.load(f\"{PATH}/Conditional_Gen_Model_Data/mira_cache.npz\")\n",
    "\n",
    "# One model from each family\n",
    "models_to_plot = [\"CDM V1\", \"CVAE V1\"]\n",
    "\n",
    "L = 100\n",
    "fig, (ax_top, ax_bottom) = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=1,\n",
    "    figsize=(6, 6),\n",
    "    gridspec_kw={'hspace': 0.1}\n",
    ")\n",
    "\n",
    "FONTSIZE = 17\n",
    "LW = 1.5\n",
    "ALPHA = 0.9\n",
    "MARKERDGEWIDTH = 1.5\n",
    "MARKERSIZE = 10\n",
    "ELINEWIDTH = 2\n",
    "CAPSIZE = 10\n",
    "DECREASE_SIZE = 4\n",
    "\n",
    "# Top panel: MIRA training curves\n",
    "plot_mira_training_curves(\n",
    "    ax=ax_top,\n",
    "    cache=cache,\n",
    "    models=models_to_plot,\n",
    "    colors_hex=[data_colors_hex[0], data_colors_hex[2]],  # CDM color, CVAE color\n",
    "    L=L,\n",
    "    ylabel='MIRA Score',\n",
    "    xlabel='Epoch',\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    markersize_trail=5,\n",
    "    markersize_final=MARKERSIZE+6,\n",
    "    markeredgewidth=MARKERDGEWIDTH,\n",
    "    alpha_trail=0.3,\n",
    "    alpha_final=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE,\n",
    ")\n",
    "\n",
    "plot_validation_result(\n",
    "    ax=ax_bottom, \n",
    "    experiment_type='conditional_distribution', \n",
    "    data_colors_hex=[data_colors_hex[0], data_colors_hex[2]],\n",
    "    lw=LW,\n",
    "    fontsize=FONTSIZE,\n",
    "    alpha=ALPHA,\n",
    "    decrease_size=DECREASE_SIZE \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "fig.set_constrained_layout(True)\n",
    "fig.savefig('../plots/pdf/MIRA_CModel_PLot.pdf')\n",
    "fig.savefig('../plots/png/MIRA_CModel_PLot.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202284aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
